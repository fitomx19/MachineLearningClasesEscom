{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class validation_set:\n",
    "    \n",
    "    def __init__(self, X_train, y_train, X_test, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_set:\n",
    "    \n",
    "    def __init__(self, X_test, y_test):\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_set:\n",
    "    \n",
    "    def __init__(self, validation_set, test_set):\n",
    "        self.validation_set = validation_set\n",
    "        self.test_set = test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(name_file, data, col_names, list_opt = False):\n",
    "    new_data = data.tolist()\n",
    "\n",
    "    with open(name_file, 'w', newline='') as f:\n",
    "        if list_opt:\n",
    "            new_new_data = [[i] for i in new_data]\n",
    "        else:\n",
    "            new_new_data = new_data\n",
    "        write = csv.writer(f)\n",
    "        write.writerow(col_names)\n",
    "        write.writerows(new_new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_test(file_name):\n",
    "    df = pd.read_csv(file_name, sep = ',', engine = 'python')\n",
    "    X = df.drop('RainTomorrow', axis = 1).values\n",
    "    y = df['RainTomorrow'].values\n",
    "    columns_names = list(df.columns)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True)\n",
    "    X_columns = columns_names[:len(columns_names) - 1]\n",
    "    y_columns = columns_names[len(columns_names) - 1:]\n",
    "    return [X_train, y_train, X_test, y_test, X_columns, y_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_folds(data, k):\n",
    "    X_train = data[0]\n",
    "    y_train = data[1]\n",
    "    X_test = data[2]\n",
    "    y_test = data[3]\n",
    "    X_columns = data[4]\n",
    "    y_columns = data[5]\n",
    "    print('Cross Validation k =', k)\n",
    "    validation_sets = []\n",
    "    kf = KFold(n_splits = k)\n",
    "    c = 0\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        c = c + 1\n",
    "        X_train_v, X_test_v = X_train[train_index], X_train[test_index]\n",
    "        y_train_v, y_test_v = y_train[train_index], y_train[test_index]\n",
    "        validation_sets.append(validation_set(X_train_v, y_train_v, X_test_v, y_test_v))\n",
    "        create_csv(name_file = \"./data_validation_train_\" + str(k) + \"_\" + str(c) + \".csv\", \n",
    "                    data = X_train_v, col_names = X_columns)\n",
    "        create_csv(name_file = \"./data_test_\" + str(k) + \"_\" + str(c) + \".csv\", \n",
    "                    data = X_test_v, col_names = X_columns)\n",
    "        create_csv(name_file = \"./target_validation_train_\" + str(k) + \"_\" + str(c) + \".csv\", \n",
    "                    data = y_train_v, col_names = y_columns, list_opt = True)\n",
    "        create_csv(name_file = \"./target_test_\" + str(k) + \"_\" + str(c) + \".csv\", \n",
    "                    data = y_test_v, col_names = y_columns, list_opt = True)        \n",
    "    my_test_set = test_set(X_test, y_test)\n",
    "    my_data_set = data_set(validation_sets, my_test_set) \n",
    "    return (my_data_set)\n",
    "data = generate_train_test('./weatherAUS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation k = 3\n",
      "Cross Validation k = 5\n",
      "Cross Validation k = 10\n"
     ]
    }
   ],
   "source": [
    "ks = [3,5,10]\n",
    "for k in ks:\n",
    "    new_data = generate_folds(data, k)\n",
    "    \n",
    "    dataset_file = open('./weatherAUS' + str(k) + '.pkl', 'wb')\n",
    "    pickle.dump(new_data, dataset_file)\n",
    "    dataset_file.close()\n",
    "\n",
    "create_csv(name_file = \"./data_test.csv\", data = new_data.test_set.X_test, col_names = data[4])\n",
    "create_csv(name_file = \"./target_test.csv\", data = new_data.test_set.y_test, col_names = data[5], list_opt = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8045260058ce78d91bfcba6f26a8332d255756bd7658ea995399a8c233e7bf8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
